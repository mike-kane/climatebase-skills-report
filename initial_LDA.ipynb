{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import LdaMulticore\n",
    "\n",
    "import spacy\n",
    "\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>labels</th>\n",
       "      <th>token_description</th>\n",
       "      <th>token_title</th>\n",
       "      <th>tfidf_title</th>\n",
       "      <th>tfidf_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Strategic Marketing &amp; Brand Design Intern</td>\n",
       "      <td>&lt;p&gt;We're looking for a badass intern that can ...</td>\n",
       "      <td>Food &amp; Agriculture</td>\n",
       "      <td>looking badass intern join team hit ground run...</td>\n",
       "      <td>strategic marketing brand design intern</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Community Manager</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Who We Are&lt;/strong&gt;&lt;/p&gt;\\n&lt;p&gt;We are ...</td>\n",
       "      <td>Energy, Buildings &amp; Cities</td>\n",
       "      <td>soontobe launched notforprofit business accele...</td>\n",
       "      <td>community manager</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Senior EE Hardware Architect/Design - Infotain...</td>\n",
       "      <td>&lt;p&gt;&lt;em&gt;At SERES, we&amp;rsquo;re forging a new kin...</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>seres wersquore forging new kind mobility comp...</td>\n",
       "      <td>senior ee hardware architectdesign infotainment</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Retail Specialist, Berkeley</td>\n",
       "      <td>&lt;b&gt;Why We’re Rad (about us): &lt;/b&gt;&lt;br /&gt;&lt;span s...</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>rad power bike mission get people onto bike el...</td>\n",
       "      <td>retail specialist berkeley</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Customer Care Associate</td>\n",
       "      <td>&lt;div&gt;\\r\\n&lt;div&gt;About Imperfect&lt;/div&gt;\\r\\n&lt;div&gt;&amp;n...</td>\n",
       "      <td>Food &amp; Agriculture</td>\n",
       "      <td>imperfect nbsp imperfect food founded mission ...</td>\n",
       "      <td>customer care associate</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0          Strategic Marketing & Brand Design Intern   \n",
       "1           1                                  Community Manager   \n",
       "2           2  Senior EE Hardware Architect/Design - Infotain...   \n",
       "3           3                        Retail Specialist, Berkeley   \n",
       "4           4                            Customer Care Associate   \n",
       "\n",
       "                                         description  \\\n",
       "0  <p>We're looking for a badass intern that can ...   \n",
       "1  <p><strong>Who We Are</strong></p>\\n<p>We are ...   \n",
       "2  <p><em>At SERES, we&rsquo;re forging a new kin...   \n",
       "3  <b>Why We’re Rad (about us): </b><br /><span s...   \n",
       "4  <div>\\r\\n<div>About Imperfect</div>\\r\\n<div>&n...   \n",
       "\n",
       "                       labels  \\\n",
       "0          Food & Agriculture   \n",
       "1  Energy, Buildings & Cities   \n",
       "2              Transportation   \n",
       "3              Transportation   \n",
       "4          Food & Agriculture   \n",
       "\n",
       "                                   token_description  \\\n",
       "0  looking badass intern join team hit ground run...   \n",
       "1  soontobe launched notforprofit business accele...   \n",
       "2  seres wersquore forging new kind mobility comp...   \n",
       "3  rad power bike mission get people onto bike el...   \n",
       "4  imperfect nbsp imperfect food founded mission ...   \n",
       "\n",
       "                                       token_title              tfidf_title  \\\n",
       "0          strategic marketing brand design intern  [0. 0. 0. ... 0. 0. 0.]   \n",
       "1                                community manager  [0. 0. 0. ... 0. 0. 0.]   \n",
       "2  senior ee hardware architectdesign infotainment  [0. 0. 0. ... 0. 0. 0.]   \n",
       "3                       retail specialist berkeley  [0. 0. 0. ... 0. 0. 0.]   \n",
       "4                          customer care associate  [0. 0. 0. ... 0. 0. 0.]   \n",
       "\n",
       "         tfidf_description  \n",
       "0  [0. 0. 0. ... 0. 0. 0.]  \n",
       "1  [0. 0. 0. ... 0. 0. 0.]  \n",
       "2  [0. 0. 0. ... 0. 0. 0.]  \n",
       "3  [0. 0. 0. ... 0. 0. 0.]  \n",
       "4  [0. 0. 0. ... 0. 0. 0.]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = pd.read_csv('jobs_df')\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking through some of the descriptions, most of the job postings have some kind of list that has key information. The first step is to collect that information. We can run an LDA on all lists such as \"responsibilities\", \"Qualifications\" or \"position description\". The first pass is just to create a basic LDA and see what we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_in_tag = [\n",
    "    \"responsibilities\", \n",
    "    \"qualifications\", \n",
    "    \"about you\", \n",
    "    \"a plus\", \n",
    "    \"what youll be doing\", \n",
    "    \"what youll do\",\n",
    "    \"you will\",\n",
    "    \"skills\",\n",
    "    'the ideal candidate',\n",
    "    'attributes',\n",
    "    'duties',\n",
    "    'prerequisites',\n",
    "    'position description',\n",
    "    'requirements'\n",
    "]\n",
    "\n",
    "def is_in_contents(tag, tag_list):\n",
    "    for key in tag_list:\n",
    "        if key in re.sub(r'[^\\w\\s]', '', tag.get_text().lower()):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_relevant_list(job_postings, tag_list):\n",
    "    \"\"\" job_postings is a list of job html descriptors. This function \n",
    "    returns a dictionary for each listing that indicates what list if any\n",
    "    of the relevant lists were in the posting\"\"\"\n",
    "    tracker = []\n",
    "    for job in job_postings:\n",
    "        soup = BeautifulSoup(job, 'html.parser')\n",
    "        track_ind={}\n",
    "        for tag in soup.find_all(True):\n",
    "            if tag.name in ['h3', 'h2', 'h1', 'strong', 'span', 'p'] and is_in_contents(tag, tag_list) and len(re.sub(r'[^\\w\\s]', '', tag.get_text().lower()).split(' '))<25:\n",
    "                entry = re.sub(r'[^\\w\\s]', '', tag.get_text().lower())\n",
    "                track_ind[entry]=0\n",
    "                for next_tags in tag.find_all_next()[:4]:\n",
    "                    if next_tags.name in ['ol', 'ul'] and track_ind[entry]==0:\n",
    "                        track_ind[entry] = next_tags.get_text()\n",
    "        tracker.append(track_ind)  \n",
    "    return tracker\n",
    "\n",
    "\n",
    "\n",
    "df_1['relevant_text']=get_relevant_list(df_1['description'].tolist(), is_in_tag)\n",
    "df_1.to_csv('processed_txt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('processed_txt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 1823 jobs listings that do not have a list with titles like \"Qualifications/ responsibilities\", out of the 17758 many jobs in the dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for i, k in enumerate(df_1['relevant_text'].tolist()):\n",
    "    if k =='{}':\n",
    "        j=j+1\n",
    "        # print(i)\n",
    "print(\n",
    "f'''\n",
    "There are {j} jobs listings that \\\n",
    "do not have a list with titles like \"Qualifications/ responsibilities\", \\\n",
    "out of the {i} many jobs in the dataset\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    BeautifulSoup(i, 'html.parser').get_text() \n",
    "    for i in df_1.description.tolist()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# get stopwords from nltk library\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def process_words(texts, stop_words=stop_words, allowed_tags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \n",
    "    \"\"\"Convert a document into a list of lowercase tokens, build bigrams-trigrams, implement lemmatization\"\"\"\n",
    "    \n",
    "    # I suspect these bigrams and trigrams are not \n",
    "    # making any real impact, I varied the threshold \n",
    "    # and did not really see much difference\n",
    "    bigram = gensim.models.Phrases(data, min_count=20, threshold=90)\n",
    "    trigram = gensim.models.Phrases(bigram[data], threshold=90)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    # remove stopwords, short tokens and letter accents \n",
    "    texts = [\n",
    "        [\n",
    "            word for word in \n",
    "            gensim.utils.simple_preprocess(\n",
    "                str(doc), deacc=True, min_len=2\n",
    "            ) \n",
    "            if word not in stop_words\n",
    "        ] for doc in texts\n",
    "    ]\n",
    "    \n",
    "    # bi-gram and tri-gram implementation\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    \n",
    "    texts_out = []\n",
    "    \n",
    "    # implement lemmatization and filter out unwanted part of speech tags\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_tags])\n",
    "    \n",
    "    # remove stopwords and short tokens again after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc), deacc=True, min_len=2) if word not in stop_words] for doc in texts_out]    \n",
    "    \n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = process_words(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 36832\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_ready)\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "print('Total Vocabulary Size:', len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.043523088506304965),\n",
      " (1, 0.05927956126072254),\n",
      " (2, 0.09597422495361731),\n",
      " (3, 0.028975340264615717),\n",
      " (4, 0.18593095864782802),\n",
      " (5, 0.14984483348928154),\n",
      " (6, 0.18097683787120056),\n",
      " (7, 0.022719094060973576),\n",
      " (8, 0.12781636054575685),\n",
      " (9, 0.04490916819302359),\n",
      " (10, 0.14962601677039822),\n",
      " (11, 0.09641722159005242),\n",
      " (12, 0.0638266765078442),\n",
      " (13, 0.032393413635367754),\n",
      " (14, 0.1326560969711348),\n",
      " (15, 0.08606590138074906),\n",
      " (16, 0.0759795569537991),\n",
      " (17, 0.04542734841187554),\n",
      " (18, 0.06392576596561733),\n",
      " (19, 0.024743229368099296),\n",
      " (20, 0.09035837674667235),\n",
      " (21, 0.09230562768603312),\n",
      " (22, 0.03658586199058109),\n",
      " (23, 0.217739181075178),\n",
      " (24, 0.07586582149649097),\n",
      " (25, 0.1447473120782141),\n",
      " (26, 0.022242206040226684),\n",
      " (27, 0.017791578884071964),\n",
      " (28, 0.14039086223941644),\n",
      " (29, 0.0682411603905896),\n",
      " (30, 0.08928023329260128),\n",
      " (31, 0.06743524323590674),\n",
      " (32, 0.07771185896675878),\n",
      " (33, 0.03599073108660291),\n",
      " (34, 0.012502572555624881),\n",
      " (35, 0.2529907213645158),\n",
      " (36, 0.1302787174793567),\n",
      " (37, 0.022730350663195488),\n",
      " (38, 0.160191606472995),\n",
      " (39, 0.13087950068377208),\n",
      " (40, 0.05619191763283556),\n",
      " (41, 0.06109328372057772),\n",
      " (42, 0.11760753374621008),\n",
      " (43, 0.040803083553659004),\n",
      " (44, 0.02620197956137141),\n",
      " (45, 0.2665372962784034),\n",
      " (46, 0.12551018844393233),\n",
      " (47, 0.1524182069274336),\n",
      " (48, 0.11650616435206038),\n",
      " (49, 0.1476610858019982),\n",
      " (50, 0.029899496345064603),\n",
      " (51, 0.033823870164657814),\n",
      " (52, 0.03340481131786639),\n",
      " (53, 0.04579183599892069),\n",
      " (54, 0.13348645848083018),\n",
      " (55, 0.023481536457086987),\n",
      " (56, 0.061599694554648636),\n",
      " (57, 0.09899536525523135),\n",
      " (58, 0.09070739286445859),\n",
      " (59, 0.06670148124384041),\n",
      " (60, 0.15511226552247015),\n",
      " (61, 0.16450452000699134),\n",
      " (62, 0.09042594039534249),\n",
      " (63, 0.13850378302769986),\n",
      " (64, 0.020810840760942518),\n",
      " (65, 0.1147272746646838),\n",
      " (66, 0.048959740460519166),\n",
      " (67, 0.11027590440007373),\n",
      " (68, 0.06846684001967733),\n",
      " (69, 0.09078843955457346),\n",
      " (70, 0.129432431484368),\n",
      " (71, 0.05335845800167478),\n",
      " (72, 0.07957492540036405),\n",
      " (73, 0.06517617810266106),\n",
      " (74, 0.1436778397750113),\n",
      " (75, 0.08107204770795137),\n",
      " (76, 0.04414622185594702),\n",
      " (77, 0.022801727997925143),\n",
      " (78, 0.0343118665718529),\n",
      " (79, 0.13395656584314528),\n",
      " (80, 0.017516286429510617),\n",
      " (81, 0.2151244212465587),\n",
      " (82, 0.1559065637324452),\n",
      " (83, 0.1978458547134574),\n",
      " (84, 0.0662393649158812),\n",
      " (85, 0.03248613716129083),\n",
      " (86, 0.08680805777076137)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_corpus = {}\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    for idx, freq in corpus[i]:\n",
    "        if id2word[idx] in dict_corpus:\n",
    "            dict_corpus[id2word[idx]] += freq\n",
    "        else:\n",
    "            dict_corpus[id2word[idx]] = freq\n",
    "            \n",
    "dict_df = pd.DataFrame.from_dict(dict_corpus, orient='index', columns=['freq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>85132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>77945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>71103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer</th>\n",
       "      <td>33962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>32986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opportunity</th>\n",
       "      <td>30765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>29683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>27299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>include</th>\n",
       "      <td>27230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skill</th>\n",
       "      <td>26810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              freq\n",
       "work         85132\n",
       "team         77945\n",
       "experience   71103\n",
       "customer     33962\n",
       "product      32986\n",
       "opportunity  30765\n",
       "company      29683\n",
       "support      27299\n",
       "include      27230\n",
       "skill        26810"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df.sort_values('freq', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 36832\n",
      "Total Vocabulary Size: 8866\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_ready)\n",
    "print('Total Vocabulary Size:', len(id2word))\n",
    "\n",
    "# Filter out words that occur less than 10 documents, or more than\n",
    "# 70% of the documents.\n",
    "id2word.filter_extremes( no_below=10, no_above=0.7)\n",
    "print('Total Vocabulary Size:', len(id2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>customer</th>\n",
       "      <td>33962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>32986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>29683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>27299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>include</th>\n",
       "      <td>27230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>26720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive</th>\n",
       "      <td>26695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process</th>\n",
       "      <td>26115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>26060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>25260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           freq\n",
       "customer  33962\n",
       "product   32986\n",
       "company   29683\n",
       "support   27299\n",
       "include   27230\n",
       "business  26720\n",
       "drive     26695\n",
       "process   26115\n",
       "ability   26060\n",
       "build     25260"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "dict_corpus = {}\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    for idx, freq in corpus[i]:\n",
    "        if id2word[idx] in dict_corpus:\n",
    "            dict_corpus[id2word[idx]] += freq\n",
    "        else:\n",
    "            dict_corpus[id2word[idx]] = freq\n",
    "            \n",
    "dict_df = pd.DataFrame.from_dict(dict_corpus, orient='index', columns=['freq'])\n",
    "dict_df.sort_values('freq', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      " Word: 0.003*\"food\" + 0.003*\"afresh\" + 0.003*\"perfect\" + 0.003*\"lime\" + 0.003*\"solar\" + 0.003*\"sale\" + 0.002*\"customer\" + 0.002*\"carboncure\" + 0.002*\"climate\" + 0.002*\"day\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      " Word: 0.005*\"convoy\" + 0.005*\"meat\" + 0.003*\"campaign\" + 0.003*\"empty\" + 0.003*\"marketing\" + 0.003*\"freight\" + 0.003*\"sale\" + 0.003*\"climate\" + 0.003*\"medium\" + 0.002*\"policy\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      " Word: 0.020*\"spin\" + 0.004*\"fulfill\" + 0.003*\"apeel\" + 0.003*\"transportation\" + 0.003*\"creativity\" + 0.003*\"chat\" + 0.003*\"city\" + 0.003*\"food\" + 0.003*\"bowery\" + 0.003*\"qualified\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      " Word: 0.006*\"und\" + 0.006*\"amp\" + 0.004*\"recycling\" + 0.004*\"robotic\" + 0.003*\"die\" + 0.003*\"pay\" + 0.002*\"food\" + 0.002*\"day\" + 0.002*\"employee\" + 0.002*\"eine\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      " Word: 0.021*\"imperfect\" + 0.013*\"food\" + 0.007*\"warehouse\" + 0.006*\"grocery\" + 0.006*\"covid\" + 0.005*\"sanitize\" + 0.005*\"confirm\" + 0.005*\"delivery\" + 0.005*\"verify\" + 0.005*\"employee\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      " Word: 0.011*\"food\" + 0.010*\"impossible\" + 0.009*\"meat\" + 0.007*\"animal\" + 0.007*\"lilium\" + 0.005*\"plant\" + 0.004*\"production\" + 0.004*\"fish\" + 0.004*\"scientific\" + 0.003*\"dairy\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      " Word: 0.016*\"campaign\" + 0.009*\"chargepoint\" + 0.005*\"charge\" + 0.005*\"vote\" + 0.004*\"public\" + 0.003*\"training\" + 0.003*\"network\" + 0.003*\"donor\" + 0.003*\"medium\" + 0.003*\"earn\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      " Word: 0.015*\"kin\" + 0.009*\"carta\" + 0.006*\"nio\" + 0.004*\"tomorrow\" + 0.003*\"client\" + 0.003*\"digital\" + 0.003*\"premium\" + 0.002*\"weather\" + 0.002*\"user\" + 0.002*\"software\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      " Word: 0.014*\"sunrun\" + 0.010*\"solar\" + 0.009*\"sale\" + 0.006*\"appointment\" + 0.006*\"retail\" + 0.005*\"shift\" + 0.005*\"sun\" + 0.004*\"planet\" + 0.004*\"residential\" + 0.004*\"entire\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      " Word: 0.006*\"energy\" + 0.004*\"solar\" + 0.004*\"form\" + 0.003*\"climate\" + 0.003*\"datum\" + 0.003*\"research\" + 0.003*\"renewable\" + 0.003*\"science\" + 0.002*\"software\" + 0.002*\"scientist\"\n",
      "\n",
      "\n",
      "Topic: 10 \n",
      " Word: 0.003*\"lucid\" + 0.003*\"planet\" + 0.003*\"luxury\" + 0.003*\"resume\" + 0.002*\"energy\" + 0.002*\"automotive\" + 0.002*\"sale\" + 0.002*\"design\" + 0.002*\"datum\" + 0.002*\"project\"\n",
      "\n",
      "\n",
      "Topic: 11 \n",
      " Word: 0.006*\"aspiration\" + 0.004*\"energyhub\" + 0.003*\"financial\" + 0.003*\"energy\" + 0.003*\"legislative\" + 0.003*\"campaign\" + 0.003*\"climate\" + 0.002*\"information\" + 0.002*\"policy\" + 0.002*\"marketing\"\n",
      "\n",
      "\n",
      "Topic: 12 \n",
      " Word: 0.009*\"cruise\" + 0.003*\"energy\" + 0.003*\"vehicle\" + 0.003*\"design\" + 0.002*\"self\" + 0.002*\"test\" + 0.002*\"engineering\" + 0.002*\"project\" + 0.002*\"software\" + 0.002*\"autonomous\"\n",
      "\n",
      "\n",
      "Topic: 13 \n",
      " Word: 0.012*\"bike\" + 0.007*\"rad\" + 0.005*\"bird\" + 0.004*\"community\" + 0.003*\"organizer\" + 0.003*\"assistance\" + 0.003*\"ebike\" + 0.003*\"seek\" + 0.003*\"radpowerbike\" + 0.003*\"power\"\n",
      "\n",
      "\n",
      "Topic: 14 \n",
      " Word: 0.018*\"infarm\" + 0.007*\"farming\" + 0.005*\"food\" + 0.004*\"farm\" + 0.004*\"fresh\" + 0.003*\"evolution\" + 0.003*\"grow\" + 0.003*\"production\" + 0.003*\"esmc\" + 0.003*\"plant\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import gensim\n",
    "num_topics = 15\n",
    "lda_model_tfidf = LdaMulticore(\n",
    "    corpus, \n",
    "    num_topics=num_topics, \n",
    "    id2word=id2word, \n",
    "    passes=2, \n",
    "    workers=4\n",
    ")\n",
    "\n",
    "\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(\n",
    "    corpus_tfidf, \n",
    "    num_topics=num_topics, \n",
    "    id2word=id2word, \n",
    "    passes=2, \n",
    "    workers=4\n",
    ")\n",
    "\n",
    "\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print(f'Topic: {idx} \\n Word: {topic}\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
